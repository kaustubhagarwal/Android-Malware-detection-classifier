import features_selection
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
import time
import pandas as pd
import os
import features_extraction
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,
                             recall_score, f1_score, classification_report)
import dask_ml.model_selection as dcv

def print_metrices_out(y_predicted, y_test):
    print("Accuracy is %f (in percentage)" %
          (accuracy_score(y_test, y_predicted) * 100))
    print("Confusion Matrix: \n" + str(confusion_matrix(y_test, y_predicted)))
    print("Recall score is %f." % recall_score(y_test, y_predicted))
    print("Precision score is %f." %
          precision_score(y_test, y_predicted))
    print("F1 score is %f." % f1_score(y_test, y_predicted))
    print("classification Report: \n" +
          str(classification_report(y_test, y_predicted)))
    print("-----------------------------------\n")

def train_svm(x_train, y_train, x_test, y_test):
    print("\n-------------SVM Model-------------")
    model = SVC(gamma='scale', probability=True)
    model.fit(x_train, y_train)
    y_predicted = model.predict(x_test)
    print("SVM Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    ns_probs = [0 for _ in range(len(y_test))]
    ns_auc = roc_auc_score(y_test, ns_probs)
    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = model.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='SVM')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()


def train_svm_tuning_c_val(x_train, y_train, x_test, y_test, c_value):
    print("-------------SVM, C value Model-------------")
    print("C value: " + str(c_value))
    model = SVC(gamma='scale', C=c_value, probability=True)
    model.fit(x_train, y_train)
    y_predicted = model.predict(x_test)
    print("SVM, tuned C val Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = model.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='SVM TUNING CVAL: '+str(c_value))
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()


def train_recursive_feature_elimination(x_train, y_train, x_test, y_test):
    print("-------------RFE Model-------------")
    model = LogisticRegression(solver='lbfgs')
    rfe = RFE(model, 4)
    rfe.fit(x_train, y_train)
    y_predicted = rfe.predict(x_test)
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = rfe.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Recursive Feature Elimination')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_extra_trees(x_train, y_train, x_test, y_test):
    print("-------------Extra Trees Model-------------")
    extra_trees = ExtraTreesClassifier(n_estimators=100)
    extra_trees.fit(x_train, y_train)
    y_predicted = extra_trees.predict(x_test)
    print("ET Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = extra_trees.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Extra Trees')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_extra_trees_n_estimators(x_train, y_train, x_test, y_test,
                                   number_estimators):
    print("-------------Extra Trees Model-------------")
    print("Number of estimators: " + str(number_estimators))
    extra_trees = ExtraTreesClassifier(n_estimators=number_estimators)
    extra_trees.fit(x_train, y_train)
    y_predicted = extra_trees.predict(x_test)
    print("ET Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = extra_trees.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Extra Trees:'+str(number_estimators)+" estimators")
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_extra_trees_n_jobs(x_train, y_train, x_test, y_test, n_jobs):
    print("-------------Extra Trees Model-------------")
    extra_trees = ExtraTreesClassifier(n_jobs=n_jobs)
    extra_trees.fit(x_train, y_train)
    y_predicted = extra_trees.predict(x_test)
    print("ET Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = extra_trees.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Extra Trees: ' + str(n_jobs)+ " jobs")
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_rf(x_train, y_train, x_test, y_test):
    print("-------------RF Model-------------")
    model = RandomForestClassifier(n_estimators=100)
    model.fit(x_train, y_train)
    y_predicted = model.predict(x_test)
    print("RF Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = model.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='RF')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()


def train_rf_number_jobs(x_train, y_train, x_test, y_test, number_of_jobs):
    print("-------------RF Model with nJobs-------------")
    print("N_Jobs: " + str(number_of_jobs))
    model = RandomForestClassifier(n_estimators=100, n_jobs=number_of_jobs)
    model.fit(x_train, y_train)
    y_predicted = model.predict(x_test)
    print("RF Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = model.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='RF: '+str(number_of_jobs)+" jobs")
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_rf_number_jobs_estimators(x_train, y_train, x_test, y_test,
                                    numbers_estimators, number_of_jobs):
    print("-------------RF Model with nJobs-------------")
    print("N_Jobs: " + str(number_of_jobs))
    print("N_Estimators: " + str(numbers_estimators))
    model = RandomForestClassifier(
        n_estimators=numbers_estimators, n_jobs=number_of_jobs)
    model.fit(x_train, y_train)
    y_predicted = model.predict(x_test)
    print("RF Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = model.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='RF: '+str(number_of_jobs)+" jobs and "+str(numbers_estimators)+ " estimators")
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def train_naive_bayes(x_train, y_train, x_test, y_test):
    print("-------------NB Model-------------")
    bern_naive_bayes = BernoulliNB()
    bern_naive_bayes.fit(x_train, y_train)
    y_predicted = bern_naive_bayes.predict(x_test)
    print("NB Evaluation parameters:")
    print_metrices_out(y_predicted, y_test)
    lr_auc = roc_auc_score(y_test, y_predicted)
    print("AUC Score: " + str(lr_auc))
    y_predicted = bern_naive_bayes.predict_proba(x_test)
    y_predicted = y_predicted[:,1]
    lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted)
    plt.plot(lr_fpr, lr_tpr, marker='.', label='Naive Bayes')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def get_partcnd(malwares, dataset_path):
    dangerous_API_Calls = []
    api = []
    api_size=[0,0,0,0,0,0,0]
    for i in range(100):
        dangerous_API_Calls.append(os.path.join(os.getcwd(), 'drebin', 'feature_vectors', malwares[i]))
    m_j = []
    n_ij= []
    tf = []
    for i in range(100):
        total_sum = 0
        mini_n_ij = []
        if((dangerous_API_Calls[i])>7):
            total_len = 7
        else:
            total_len = len(dangerous_API_Calls[i])
        for j in range(total_len):
            total_sum+=dangerous_API_Calls[i][j]
            mini_n_ij.append(dangerous_API_Calls[i][j])
        n_ij.append(mini_n_ij)
        m_j.append(total_sum)
        tf_ij = []
        for j in range(total_len):
            tf_ij.append(mini_n_ij[j]/total_sum)
        tf.append(tf_ij)
        for api_type in dangerous_API_Calls:
            for k in range(total_len):
                if(api[k] in dangerous_API_Calls[i]):
                    api_size[k]+=1
    idf_val = []
    for i in range(len(api_size)):
        idf_val.append(math.log(len(dangerous_API_Calls)/api_size[i]))
    arr = ['ID', 'Parameter', 'API-1','API-2', 'API-3', 'API-4', 'API-5', 'API-6', 'API-7']
    print(arr)
    for i in range(100):
        another_arr = []
        another_arr.append(i)
        another_arr.append('Np')
        for j in range(7):
            another_arr.append(n_ij[i][j])
        print(another_arr)
        another_arr = []
        another_arr.append(i)
        another_arr.append('TFp')
        for j in range(7):
            another_arr.append(tf[i][j])
        print(another_arr)
        another_arr = []
        another_arr.append(i)
        another_arr.append('IDFp')
        for j in range(7):
            another_arr.append(idf_val[i])
        print(another_arr)
        another_arr = []
        another_arr.append(i)
        another_arr.append('Wp')
        for j in range(7):
            another_arr.append(idf_val[i]*tf[i][j])
        print(another_arr)

def read_data():
    print('Reading data from CSV file...')
    malwares = pd.read_csv('C:\\Users\\Kaustubh Agarwal\\OneDrive\\Desktop\\DRDO Docs\\Code\\malware-analysis-master\\drebin\\sha256_family.csv', dtype=str)
    print('Found (' + str(len(malwares.index)) + ') malwares in csv file.')
    data_path = 'C:\\Users\\Kaustubh Agarwal\\OneDrive\\Desktop\\DRDO Docs\\Code\\malware-analysis-master\\drebin\\feature_vectors'
    features_vector_path = data_path
    dataset_files = os.listdir(features_vector_path)
    dataset_files_length = len(dataset_files)
    print('Found (' + str(dataset_files_length) + ') files to classify.') 
    malware_files = []
    not_malware_files = []
    for file_name in dataset_files:
        if file_name in (malwares.values[:, 0]):
            malware_files.append(file_name)
        else:
            not_malware_files.append(file_name)

    malware_files_length = len(malware_files)
    not_malware_files_length = len(not_malware_files)
    print('Found (' + str(malware_files_length) + ') malware files.')
    print('Found (' + str(not_malware_files_length) + ') safe files.')

    #get_partcnd(malwares, dataset_files)

    x = []
    y = []

    for malware_file in malware_files:
        with open(data_path + '/' + malware_file, 'r') as file:
            file_content = file.read().splitlines()
            sample = features_extraction.extract_features(file_content)
            x.append(sample)
            y.append(1)

    counter = 1  
    for non_malware_file in not_malware_files:
        counter += 1
        if(counter == malware_files_length):
            break
        else:
            with open(data_path + '/' + non_malware_file, 'r') as file:
                file_content = file.read().splitlines()
                sample = features_extraction.extract_features(file_content)
                x.append(sample)
                y.append(0)

    x = np.array(x)
    y = np.array(y)
    print("\nFeatures & Labels arrays' shapes, respectively: " +
          str(x.shape), str(y.shape))
    return x, y

x, y = read_data()

print('\nFeatures Selection based on KBest: ')
features_selection.select_features_k_best(x, y)

print('\nFeatures Selection based on Recursive Features Elimination: ')
features_selection.select_features_recursive_feature_elimination(x, y)

print('\nFeatures Selection based on Extra trees classifier: ')
features_selection.select_features_extra_trees(x, y)

print('\nFeatures Selection based on Random Forest classifier: ')
features_selection.select_features_random_forest(x, y)

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42)

print('\nTraining data shape (x, y): ' +
      str(x_train.shape), str(y_train.shape))

print('\nTesting data shape (x, y): ' +
      str(x_test.shape), str(y_test.shape))

train_svm(x_train, y_train, x_test, y_test)
train_svm_tuning_c_val(x_train, y_train, x_test, y_test, 10)
train_svm_tuning_c_val(x_train, y_train, x_test, y_test, 100)
train_svm_tuning_c_val(x_train, y_train, x_test, y_test, 1000)

t_start = time.time()
train_rf(x_train, y_train, x_test, y_test)
t_finish = time.time()
print(round((t_finish - t_start), 2), "Time to finish with default nJobs\n")

t_start_1 = time.time()
train_rf_number_jobs(x_train, y_train, x_test, y_test, 10)
t_finish_1 = time.time()
print(round((t_finish_1 - t_start_1), 2), "Time to finish with 10 nJobs\n")

t_start_2 = time.time()
train_rf_number_jobs_estimators(
    x_train, y_train, x_test, y_test, 1000, 10)
t_finish_2 = time.time()
print(round((t_finish_2 - t_start_2), 2),
      "Time to finish with 10 nJobs and 1000 nEstimators\n")

t_start_3 = time.time()
train_extra_trees(x_train, y_train, x_test, y_test)
t_finish_3 = time.time()
print(round((t_finish_3 - t_start_3), 2),
      "Time to finish ET with 100 nEstimators\n")

t_start_4 = time.time()
train_extra_trees_n_estimators(x_train, y_train, x_test, y_test, 500)
t_finish_4 = time.time()
print(round((t_finish_4 - t_start_4), 2),
      "Time to finish ET with 500 nEstimators\n")

t_start_5 = time.time()
train_extra_trees_n_estimators(x_train, y_train, x_test, y_test, 1000)
t_finish_5 = time.time()
print(round((t_finish_5 - t_start_5), 2),
      "Time to finish ET with 1000 nEstimators\n")

t_start_6 = time.time()
train_extra_trees_n_jobs(x_train, y_train, x_test, y_test, 10)
t_finish_6 = time.time()
print(round((t_finish_6 - t_start_6), 2),
      "Time to finish ET with 100 nJobs\n")

t_start_7 = time.time()
train_extra_trees_n_jobs(x_train, y_train, x_test, y_test, 500)
t_finish_7 = time.time()
print(round((t_finish_7 - t_start_7), 2),
      "Time to finish ET with 500 nJobs\n")

t_start_8 = time.time()
train_extra_trees_n_jobs(x_train, y_train, x_test, y_test, 1000)
t_finish_8 = time.time()
print(round((t_finish_8 - t_start_8), 2),
      "Time to finish ET with 1000 nJobs\n")

train_recursive_feature_elimination(x_train, y_train, x_test, y_test)

train_naive_bayes(x_train, y_train, x_test, y_test)
